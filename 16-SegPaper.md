# 1. 修改deeplab，简化语义标签，提高实时性。
# 2. 在MultiNet基础上修改，完成道路分割、车辆、行人等检测。
# 3. 打破FCN Encoder-Decoder架构,设计one step end-to-end网络。预测语义分割每一类物体在图片上的像素轮廓，而不是端到端输出图片。
# 4. 将pooling层换成边缘检测层试一下效果。
## 使用ResNet实现的分割网络效果state-of-art. 

# 2019.01.08
* 跑通KittiSeg evaluate.py程序	yes
* 整理KittiSeg和MultiNet代码		yes

# 2019.01.09计划(评价指标)
## 阅读MaxF1论文(THE KITTI-ROAD DATASET)
* [blog1](https://blog.csdn.net/sinat_28576553/article/details/80258619)
* ego-lane vs.opposing lane,(自我车道与对方车道)
* 2D Bird’s Eye View (BEV) space.
* For methods that output confidence maps (in contrast to binary road classification), the classification threshold τ is chosen to maximize the F-measure.
* 
## IOU?

# 2019.01.13
## 评价MultNet训练结果
```python
segmentation Evaluation Finished. Results
Raw Results:
[train] MaxF1 (raw)    :  98.9767 
[train] BestThresh (raw)    :  68.2353 
[train] Average Precision (raw)    :  92.5437 
[val] MaxF1 (raw)    :  95.9975 
[val] BestThresh (raw)    :  14.9020 
[val] Average Precision (raw)    :  92.3125 
Speed (msec) (raw)    :  42.8566 
Speed (fps) (raw)    :  23.3336
```
## 读AP指标（VOC DATASET）
* [AP wiki](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision)
* [blog1](https://blog.csdn.net/niaolianjiulin/article/details/53098437)
* [blog2](https://blog.csdn.net/hysteric314/article/details/54093734)
* 以recall为横坐标（0~1），precision为纵坐标（0~1）作图。得到一条曲线。该曲线下的面积即为AP.
* $ AP=\int_0^1 {p(r)}\r$ 

# 2019.01.14计划
## 标注Cityscape数据集
* [blog1](https://blog.csdn.net/fabulousli/article/details/78633531)
* [labelme 工具](https://github.com/wkentaro/labelme) 				yes

# 2019.01.15
## 发现好博客
* [深度学习数据集介绍及相互转换](https://www.cnblogs.com/ranjiewen/p/9860953.html)
## labelme 工具生成Kitti Road数据集：			yes
* img.putpalette([0,0,0,0,255,0,0,0,255])	
## labelme 工具生成CityScapes数据集：			yes
* from cityscapesscripts.helpers.labels     import name2label 
## cityscapesScripts标注自己图片				no

# 2019.01.16计划
* [Semantic Segmentation using Fully Convolutional Networks over the years](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html)

# 2019.01.19 
## [Semantic Segmentation using Fully Convolutional Networks over the years]					yes
* [visualization of FCN](http://ethereon.github.io/netscope/#/preset/fcn-8s-pascal)
* [vis of common networks](http://ethereon.github.io/netscope/quickstart.html)
* [Deconvolutions](https://distill.pub/2016/deconv-checkerboard/)
* LinkNet: A feature map with shape [H, W, n_channels] is first convolved with a 1*1 kernel to get a feature map with shape [H, W, n_channels / 4 ] and then a deconvolution takes it to [2*H, 2*W, n_channels / 4 ] a final 1*1 kernel convolution to take it to [2*H, 2*W, n_channels / 2 ]. Thus the decoder block fewer parameters due to this channel reduction scheme.

# 2019.01.20 计划
## [Deconvolutions](https://distill.pub/2016/deconv-checkerboard/)
* When we look very closely at `images generated by neural networks`, we often see a strange `checkerboard pattern` of artifacts.
* `In theory`, our models could learn to carefully write to unevenly overlapping positions so that the output is evenly balanced; `In fact`, not only do models with uneven overlap not learn to avoid this, but models with even overlap often learn kernels that cause similar artifacts! 
* Better Upsampling
> `One approach` is to make sure you use `a kernel size that is divided by your stride`, avoiding the overlap issue.
> Another approach is `resize the image (using nearest-neighbor interpolation or bilinear interpolation) and then do a convolutional layer`.
* We don’t necessarily think that either approach is the final solution to upsampling, but they do fix the checkerboard artifacts.
* Whenever we `compute the gradients of a convolutional layer`, we do `deconvolution` (transposed convolution) on the `backward pass`.
## [2017-course_by_Tao Kong.pdf]
* The region proposal network is a FCN which outputs `K*(4+2) sized vectors`.
* `Mask R-CNN` = Faster R-CNN with FCN on ROIs.
* Useful links for learning detection:
> RCNN/Fast R-CNN/Faster R-CNN: https://github.com/rbgirshick
> YOLO/YOLOv2: https://pjreddie.com/darknet/yolo/
> SSD: https://github.com/weiliu89/caffe/tree/ssd
> R-FCN: https://github.com/daijifeng001/R-FCN
> Tensorflow detector:https://github.com/tensorflow/models/tree/master/research/object_detection
